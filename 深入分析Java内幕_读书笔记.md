# 一、Web请求

## 1.HTTP解析

* 请求头
* 响应头
* ctrl+F5强制请求服务器，不走缓存，请求头会新增`Pragma:no-cache`和`Cache-Control:no-cache`

## 2.DNS域名解析

1. 浏览器检查缓存中有没有这个域名对应的解析过的IP，如果有解析过程结束。

2. 如果没有，查找操作系统的hosts文件，是否有对应映射。可能导致域名劫持。

3. 如果hosts没有映射，操作系统会把这个域名发送给LDNS，本地区的域名服务器，就是本机配置网络的DNS。

4. 如果LDNS还没有命中，就直接向Root Server域名服务器请求解析。

5. 跟域名服务器返回给本地域名服务器一个所查询域的主域名服务器地址，gTLD。

6. 本地域名服务器再向上一步返回的gTLD服务器发送请求。

7. 接收请求的gTLD服务器查找并返回此域名对应的Name Server域名服务器的地址，这个Name Server通常是自己注册的域名服务器。

8. Name Server域名服务器会查询存储的域名和IP的映射关系表，正常情况下得到域名对应的IP和一个TTL值返回给DNS Server域名服务器。

9. 返回该域名对应的IP和TTL值，Local DNS Server会缓存这个域名和IP的对应关系，缓存时间由TTL值控制。

10. 把解析的结果返回给用户，用户根据TTL值缓存在本地系统缓存中，域名解析过程完毕。

    ![img](https://img-blog.csdn.net/20171211190812796?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzc4MTI1MTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)  

## 3.CDN工作机制

### 3.1 概念

CDN是内容分布网络，是一种先进的流量分配网络。在Internet上增加一层新的网络架构，将网站内容发布到最接近用户的网络“边缘”，是用户可以就近取得所需的内容，提高响应速度。例如：缓存网络中的静态资源，CSS、JS、图片和静态页面等数据。

### 3.2 目的

* 可扩展。
  * 性能可扩展：应对新增的大量数据、用户和事务的扩展能力。
  * 成本可扩展性：用低廉的运营成本提供动态的服务能力和高质量的内容分发。
* 安全性。强调提供物理设备、网络、软件、数据和服务过程的安全性，减少因为DDOS攻击或其他恶意行为造成商业网站的业务中断。
* 可靠性、响应和执行。服务可用性指能够处理可能的故障和用户体验下降的问题，通过负载均衡及时提供网络的容错机制。

### 3.3 负载均衡

​	负载均衡就是对工作任务进行平衡、分摊到多个操作单元上执行，如图片服务器、应用服务器，共同完成工作任务。可以提高服务器响应速度及利用率，避免软件或者硬件模块单点失效，解决网络拥塞问题，实现地理位置无关性，为用户提供较一致的访问质量。

* 链路负载均衡。链路负载均衡由DNS解析完成，用户最终访问哪个Web Server有DNS Server控制，由Global DNS Server动态解析域名服务。
  * 优点：用户直接访问目标服务器，不需要经过其他代理服务器，访问速度更快。
  * 缺点：由于DNS在用户本地和Local DNS Server都有缓存，一旦某台Web Server挂点，很难及时更新域名解析缓存，导致用户无法访问该域名。
* 集群负载均衡。
  * 硬件负载均衡。F5，价格贵但是支持较好。
  * 软件负载均衡。成本低，会有代理服务器，增加网络成本。
    * LVS，四层负载，网络层利用IP地址进行转发。
    * HAProxy，七层负载，根据访问的HTTP请求头来进行负载均衡，如根据不同URL将请求转发到特定集群或者根据用户Cookie信息来指定访问机器。
* 操作系统负载均衡。利用操作系统级别的软中断和硬中断达到负载均衡，如可以设置多队列网卡来实现。

### 3.4 CDN动态加速

​	CDN动态加速是目前比较流行的一种优化技术，其原理就是在CDN的DNS解析中通过动态的链路探测来寻找回源最后的一条路径，然后通过DNS的调度将所有请求调度到选定的这条路径上回源，从而加速用户访问效率。

​	由于CDN节点遍布全国，所有用户接入一个CDN节点后，可以选择一条从离用户最近的CDN节点到源站链路最好的路径让用户走。一个简单的原则就是每个CDN节点从源站上下载一个一定大小的文件，看哪个链路的总耗时最短，这个可以构成一个链路列表，然后绑定在一个DNS解析上，更新到CDN的Local DNS上。

# 二、深入分析Java I/O工作机制

## 1. Java I/O类库基本架构

* 基于字节操作的I/O接口：`InputStream`和`OutputStream`
* 基于字符操作的I/O接口：`Writer`和`Reader`
* 基于磁盘操作的I/O接口：`File`
* 基于网络操作的I/O接口：`Socket`

## 2. 磁盘I/O的工作机制

### 2.1 访问文件的方式

* 标准访问文件的方式

  * 当程序调用read()接口时，操作系统会检查在内核的高速缓存中有没有需要的数据，如果已经有缓存，直接从缓存中返回，如果没有从磁盘中读取，然后缓存到操作系统高速缓存区。
  * 写入的方式是，用户应用调用write()接口时，将数据从用户地址空间复制到内核地址空间的缓存中，这时对用户来说，写操作已完成，什么时候写入磁盘中由操作系统决定，除非显式调用sync同步命令。

* 直接I/O的方式

  ​	直接I/O的方法就是直接访问磁盘，不经过操作系统高速缓存区，减少了一次从内核缓冲区到用户程序缓存的数据复制。例如：热点数据预加载，提高访问速度。

* 同步访问文件的方式

  ​	与标准I/O方式不同，它成功的标志是数据写入磁盘才返回成功。

* 异步访问文件的方式

  ​	当访问文件的线程发出请求之后，线程会接着处理其他事情，而不是阻塞等待，当请求的数据返回后继续处理下面的操作。这种访问文件的方式可以提高应用程序效率，但不会改变访问文件的效率。

* 内存映射的方式

  内存映射的方式是指操作系统将内存中的一块区域与磁盘中的文件关联起来，当要访问内存中的一段数据时，转为访问文件中的数据。减少数据从内核空间缓存到用户空间缓存的数据复制，这两个空间数据共享。

### 2.2 Java访问磁盘文件

### 2.3 Java序列化

​	将对象转为一串二进制表示的字节数组，通过保存或转移这些字节数据来达到持久化的目的。

* 父类实现`Serializable`接口时，所有子类都可以被序列化。
* 子类实现`Serializable`接口，父类没有，父类中的属性不能被序列化（不报错，数据会丢失），但是在子类中仍能正确序列化。
* 如果序列化的属性是对象，则这个对象必须实现`Serializable`接口，否则会报错。
* 在反序列化时，如果对象的属性有被修改或删除，则修改的部分属性丢失，但不会报错。
* 在反序列化时，如果serialVersionUID被修改，则反序列化会失败。

## 3. 网络I/O工作机制

​	数据从一台主机发送到网络中的另一台主机需要经过很多步骤。首先要有相互沟通的意向；其次要有能沟通的物理渠道（物理链路）；采用什么方式，是电话还是面对面交流；最后，双方语言能够交流，而且双方交流的步调要一一致，明白什么时候自己说话，什么时候该对方说话（通信协议）。

### 3.1 TCP状态转化

1. CLOSED：起始点，在超时或者连接关闭时进入此状态。
2. LISTEN：Server端在等待连接时的状态，Server端为此要调用Socket、bind、listen函数，就能进入此状态。这称为应用程序被动打开（等待客户端来连接）。
3. SYN-SENT：客户端发起连接，发送SYN给服务端。如果服务端不能连接，则进入CLOSED状态。
4. SYN-RCVD：服务端接收客户端的SYN请求，服务端由LISTEN状态进入SYN-RCVD状态。同时服务端要回应一个ACK，发送一个SYN给客户端；另一种情况是，客户端在发起SYN的同时接收到服务端的SYN请求，客户端会有SYN-SENT状态转为SYN-RCVD状态。
5. ESTABLISHED：服务端和客户端在完成3次握手后进入该状态，说明已经开始传输数据了。
6. FIN-WAIT-1：主动关闭的一方，由状态5进入此状态。具体动作是发送FIN给对方。
7. FIN-WAIT-2：主动关闭的一方，接收到对方的ACK FIN，进入此状态。由此不能再接收对方的数据，但是能够向对方发送数据。
8. CLOSE-WAIT：接收到FIN后，被动关闭的一方进入此状态。具体的动作是在接收到FIN的同时发送ACK。
9. LAST-ACK：被动关闭的一方，发起关闭请求，由状态8进入此状态。具体动作是发送FIN给对方，同时在接收ACK时进入CLOSED状态。
10. CLOSING：两边同时发起关闭请求时，由FIN-WAIT-1进入此状态。具体动作是接收到FIN请求，同时响应了一个ACK。
11. TIME-WAIT：这个状态比较复杂，也是最常见的状态，有3个状态可以转化为此状态：
    * 由FIN-WAIT-2转换到TIME-WAIT。具体情况是：在双方不同时发起FIN情况下，主动关闭的一方在完成自身发起的关闭请求后，接收到被动关闭一方的FIN后进入此状态。
    * 由CLOSING状态进入TIME-WAIT。具体情况是：在双方同时发起关闭，都做了发起FIN的请求，同时接收到FIN并做了ACK的情况下。
    * 由FIN-WAIT-1转换到TIME-WAIT。具体情况是：同时接收到FIN（对方发起）和ACK（本身发起的FIN回应），它与CLOSING进入TIME-WAIT的区别是本身发起FIN回应的ACK先与对方的FIN请求到达，而CLOSING进入TIME-WAIT则是FIN先到达。

### 3.2 影响网络传输的原因

* 网络带宽：所谓带宽就是一条物理链路在1s内能够传输的最大bit数，不是字节数，也就是b/s。
* 传输距离：数据在光纤中要走的距离，虽然光的传播速度很快，但是也需要时间，并且数据在光纤中的移动不是直线的，会有折射率，所以大概是光的2/3，这个时间也就是传输延时。
* TCP拥塞控制：TCP是一个“停-等-停-等”的协议，传输方和接收方步调要一致，要达到一致的步调需要通过拥塞来控制调节。

### 3.3 Java Socket工作机制

​	Socket概念没有对应到具体的实体，它是描述计算机之间完成网络通讯的抽象。Socket下一层是TCP/UDP和端口号，TCP/UDP下一层是IP。

### 3.4 建立通讯链路

1. 当客户端要与服务端通讯时，客户端首先创建Socket实例，操作系统为该实例分配未被使用的端口号，并创建一个包含本地地址、远程地址和端口号的套接字数据结构，这个数据结构将一直保存在系统中直到连接关闭。创建Socket实例的构造函数正确返回之前，将要进行TCP3次握手，握手完成之后，Socket实例对象将创建完成，否则抛出IOException错误。
2. 对应的，在服务端创建ServerSocket实例，一般只有指定的端口没被占用，都可以创建成功。操作系统也会创建一个底层数据结构，包含指定监听的端口号和监听地址的通配符，通常都是"*"，即监听所有地址。当调用accept()方法时，将进入阻塞状态，等待客户端的请求。ServerSocket实例维护了一个未完成连接的数据结构列表，3次握手成功，将移除。

### 3.5 数据传输

* 当连接已经建立成功之后，服务端和客户端都有一个Socket实例，每个Socket实例都有`InputStream`和`OutputStream`，并通过这连个对象完成数据交换。

* 网络I/O是以字节流传输的，当创建Socket对象时，操作系统会为`InputStream`和`OutputStream`分配一定大小的缓冲区，数据的写入和读取都是通过这个缓冲区完成的。

* 写入端将数据写入`OutputStream`的SentQ队列中，当队列填满时，数据将被转移到另一端`InputStream`的RecvQ队列中，如果这时RecvQ队列也满了，`OutputStream`的write方法将会阻塞，直到RecvQ队列有足够的空间容纳SentQ发送的数据。

  注意：缓存区的大小和写入写出端的速度大大影响数据传输效率，由于可能会发生阻塞，所以网络I/O和磁盘I/O不同的是数据的写入和读取还有一个协调的过程。

## 4. NIO的工作方式

### 4.1 BIO的问题

​	BIO即阻塞I/O，不管是服务端还是客户端都可能发生阻塞，一旦阻塞，线程将会失去CPU使用权，在高并发和有性能要求的应用上是不能被接受的。

​	部分解决方式：

* 一个客户端，对应一个处理线程，出现阻塞时也是一个线程阻塞，不会影响到其他线程工作，为了减少线程的开销，采用线程池来管理线程。

  依然存在的问题：

* 给某些客户端设置更高的服务优先级，很难通过线程的优先级来完成。

* 每个客户端的请求在服务端可能需要访问某些竞争资源，这些客户端在不同线程中，因此需要同步，但是实现同步远比单线程复杂。

### 4.2 NIO的工作机制

​	NIO引入了Buffer、Channel和Selector，类比的话，Channel相当于高铁（负责传输），Selector相当于高铁站（负责轮询调度），Buffer相当于高铁上的座位（负责存储）。

​	NIO代码实现思路：

* 调用Selector的静态工厂创建一个选择器。

* 创建服务端的Channel，绑定到一个Socket对象，并把这个通信通道注册到选择器上，把这个通信通道设置为非阻塞模式。

* 调用Selector的`selectedKeys`方法来检查已经注册在这个选择器上的所有通信通道是否有需要的事件发生。

* 如果有事件发生，返回所有的`SelectedKey`，通过这个对象的Channel方法可以取得这个通信信道对象，从而读取通信数据，这里读取的数据是Buffer，这个Buffer是我们可以控制缓冲器。

  **关键：一个线程专门负责监听客户端的连接请求，以阻塞方式执行；另一个线程专门负责处理请求。**

### 4.3 Buffer的工作方式

* Buffer简单的理解为一组基本数据类型的元素列表，通过几个变量来保存这个数据的当前位置状态，也就4个索引：
  * capacity：缓冲区数组的总长度
  * position：下一个要操作的数据元素位置
  * limit：缓冲区数组中不可操作的下一个元素位置，limit<=capacity
  * mark：用于记录当前position的前一个位置或默认是0
* 通过Channel获取的I/O数据首先要经过操作系统的Socket缓冲区，再将数据复制到Buffer中，这个操作系统的缓冲区就是底层的TCP所关联的SendQ或RecvQ队列，从操作系统缓冲区到用户缓冲区复制数据比较消耗性能，Buffer提供了一个可以直接操作系统缓冲区的方式，即`ByteBuffer.allocateDirect(size)`，这个方法返回的`DirectByteBuffer`对象就是与底层存储空间关联的缓冲区，它通过native操作非JVM内存空间。每次创建或销毁的时候都调用`Sysem.gc()`，`DirectByteBuffer`可能导致内存泄露。

### 4.4 NIO的数据访问方式

* FileChannel.transferXXX。与传统文件传输相比，可以减少数据从内核到用户空间的复制，数据再接在内核空间移动，Linux中使用sendfile系统调用。
* FileChannel.map。将文件按照一定大小块映射为内存区域，当程序访问这个内存区域时，将直接操作文件数据，省去了数据从内核空间到用户空间的复制。

## 5. I/O调优

### 5.1 磁盘I/O优化

* 性能检测。可以对应用程序进行压测，看系统的I/O wait指标是否正常，如果是4个CPU，理想的I/O wait不应该超过25%，如果超过表明I/O可能成为应用瓶颈。Linux下通过iostat查看。还有一个指标是IOPS。
* 提高I/O性能
  * 增加缓存，减少磁盘访问次数。
  * 优化磁盘管理系统，设计最优的磁盘方式策略，以及磁盘寻址策略。底层操作系统层面考虑的。
  * 设计合理的磁盘存储数据块，以及访问这个数据的块的策略。例如：给存放的数据设置索引，通过寻址索引加快和减少磁盘的访问量，还可以采用异步非阻塞的方式加快磁盘访问速度。
  * 应用合理的RAID策略提升磁盘I/O。

### 5.2 TCP网络参数调优

​	要能够建立TCP连接，必须知道对方IP和一个未使用的端口号，32位操作系统的端口号都是2个字节表示，所以共有65535（2的16次方）个，所以一台主机的能够同时建立的连接数是有限的。

* 增大端口范围，Linux有具体的文件，使用时查阅工具。

* TCP连接复用。

  Linux查看当前TCP统计情况：

  * cat /proc/net/netstat	查看TCP的统计信息
  * cat /proc/net/snmp     查看当前系统的连接情况
  * netstat -s  查看网络的统计信息

### 5.3 网络I/O优化

* 减少网络交互次数，合理设置缓存。

* 减少网络传输数据量的大小，将数据压缩后再传输。

* 尽量减少编码，网络I/O都是通过字节码传输的，通常意义的序列化。但是我们发送的数据一般都是字符形式，从字符到字节必须编码，且比较耗时。可以在传输时，提前序列化，转为字节数据再传输。

  交互方式：

* 同步阻塞：存在任务依赖，有个可靠的任务序列，要么都成功要么都失败。阻塞是CPU会空闲，CPU一个个处理。

* 同步非阻塞：非阻塞是在一个线程执行慢操作时，CPU会执行其他线程操作，等这个慢操作执行完成，CPU再接着完成后续操作。提高了CPU使用率，但是会存在系统的线程切换问题。

* 异步阻塞：异步是不可靠任务序列，无法保证任务的真正完成。

* 异步非阻塞

## 6. 适配器模式

* 把一个类的接口转换成客户端能接受的另一个接口，从而使不匹配的两个类一起工作。
* 结构
  * Target（目标接口）：所要转换成的所期待的接口
  * Adaptee（源角色）：需要适配的接口
  * Adapter（适配器）：将源接口适配成目标接口，继承原接口，适配目标接口
* I/O中的适配器
  * 将字节流转为字符流的`InputStreamReader`，目标接口`Reader`，源角色`InputStream`的实例。
  * StringReader将一个String类适配到Reader接口。
  * ByteArrayInputStream适配器将byte数组是配到InputStream流处理接口。

## 7. 装饰器模式

* 把一个类重新装扮下，使其在功能上更强大，但是作为原来这个类的使用者，不应该感受到装饰前后的任何不同，否则就破坏了原始类的结构，装饰者模式要保证对被装饰类的使用者透明。
* 结构
  * Component：实现这个抽象组件的所有功能。
  * ConcreteComponent：实现这个抽象组件的所有功能。
  * Decorator：装饰器角色，持有一个Component对象的引用，定义一个与抽象组件一致的接口。
  * ConcreteDecorator：具体的装饰器实现者，负责实现装饰器角色定义的功能。
* I/O中的装饰者模式  
  * InputStream为抽象组件。
  * FileInputStream为抽象组件具体的实现。
  * FilterInputStream类为装饰角色，实现InputStream所有接口，并维护了一个对象引用。
  * BufferedInputStream类就是装饰器具体的实现者。它可以使用InputStream所有功能，并且使得读取的数据保存在内存中，提高了读取性能。

## 8. 适配器和装饰器的区别

* 都有统一的别名“包装模式”。
* 设计目的不同：
  * 适配器模式是把一个接口转换为另一个接口，目的是通过改变接口来达到复用的目的。
  * 装饰器模式是不改变被装饰对象的接口，增强原有对象的功能，或改变原有对象的处理方式来提高性能。

